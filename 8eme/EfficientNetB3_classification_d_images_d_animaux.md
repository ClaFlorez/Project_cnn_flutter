# EfficientNetB3 pour la Classification d‚ÄôImages d‚ÄôAnimaux  
### Mod√®le CNN haute pr√©cision optimis√© pour le d√©ploiement mobile  
**Autrice : Claudia (Claud-IA)**  
**Version : 2025**

---

## üìÑ R√©sum√© (Abstract)

Ce projet pr√©sente un mod√®le de classification d‚Äôimages d‚Äôanimaux bas√© sur **EfficientNetB3** avec fine-tuning partiel, atteignant une pr√©cision d‚Äôenviron **99 %** sur un jeu de test √©quilibr√© (6 classes : √©l√©phant, girafe, l√©opard, rhinoc√©ros, tigre, z√®bre).

Plusieurs backbones ont √©t√© compar√©s, dont *MobileNetV2* et *EfficientNetB0*, et une √©tude d‚Äôablation a √©t√© r√©alis√©e pour analyser l'effet des hyperparam√®tres (learning rate, freeze ratio, dropout, class weights).

Le mod√®le final est export√© en **TensorFlow Lite (TFLite)** et valid√© pour une int√©gration temps r√©el dans une application Flutter.

---

## 1. Introduction

La classification d‚Äôimages est une t√¢che fondamentale en vision par ordinateur.  
Ce projet vise √† :

- Comparer diff√©rents backbones CNN l√©gers  
- Optimiser la pr√©cision gr√¢ce au fine-tuning  
- R√©duire la confusion entre classes proches (ex : rhino vs √©l√©phant)  
- Exporter un mod√®le TFLite pour usage mobile  
- Documenter un pipeline complet et reproductible  

---

## 2. Description du Jeu de Donn√©es

### 2.1 Classes
- elephant  
- girafe  
- leopard  
- rhino  
- tigre  
- zebre  

### 2.2 R√©partition

| Split       | Nombre d‚Äôimages |
|-------------|------------------|
| Train       | 20 400 |
| Validation  | 3 600 |
| Test        | 6 000 |

### 2.3 Organisation

```
data/
  train/
  validation/
  test/
```

---

## 3. M√©thodologie

### 3.1 Pr√©traitement
- Taille : **224 √ó 224 √ó 3**
- Pixels : **0‚Äì255**
- Normalisation : `efficientnet.preprocess_input`

### 3.2 Augmentation des donn√©es
- Rotation ¬±15¬∞  
- Translation 10 %  
- Zoom 15 %  
- Shear 10 %  
- Flip horizontal  
- Luminosit√© 0.85‚Äì1.15  

---

## 4. Architecture du Mod√®le

### 4.1 Sch√©ma g√©n√©ral

```mermaid
flowchart TD
    A[Image d'entr√©e 224√ó224√ó3] --> B[Backbone EfficientNetB3]
    B --> C[GlobalAveragePooling2D]
    C --> D[Dropout 0.3]
    D --> E[Dense 256 + BatchNorm + ReLU]
    E --> F[Dropout 0.5]
    F --> G[Dense 6 Softmax]
    G --> H[Probabilit√©s de sortie]
```

### 4.2 D√©tails de la t√™te de classification
```
GlobalAveragePooling2D
‚Üì
Dropout(0.3)
‚Üì
Dense(256) + BatchNormalization + ReLU
‚Üì
Dropout(0.5)
‚Üì
Dense(6, activation="softmax")
```

---

## 5. Configuration d‚ÄôEntra√Ænement

### 5.1 Param√®tres

| Phase | Backbone | Couches entra√Ænables | LR | √âpoques |
|-------|----------|----------------------|-----|---------|
| Phase 1 | Gel√© | 0 % | 1e-3 | 15 |
| Phase 2 | ~80 % d√©gel√© | Majorit√© | 1e-4 (LR dynamique) | 50 max |

### 5.2 Callbacks
- EarlyStopping  
- ReduceLROnPlateau  
- ModelCheckpoint  

---

## 6. √âtude d‚ÄôAblation ‚Äì Comparaison des Mod√®les

### 6.1 R√©sultats

| Mod√®le | Accuracy Test | Observations |
|--------|----------------|--------------|
| MobileNetV2 | 97‚Äì98 % | Confusion rhino ‚Üî √©l√©phant |
| EfficientNetB0 | ~98.3 % | Bon compromis |
| EfficientNetB3 (Phase 1) | ~98.5 % | Bonne base |
| **EfficientNetB3 + Fine-Tuning** | **~99 %** | Meilleur mod√®le |

### 6.2 Impact des hyperparam√®tres

| Param√®tre | Effet |
|-----------|--------|
| LR 1e-3 ‚Üí 1e-4 | Apprentissage plus stable |
| D√©-gel 0 % ‚Üí 80 % | Meilleure extraction |
| Dropout 0.3 ‚Üí 0.5 | Moins d‚Äôoverfitting |
| Class weights √ó2 | Moins de confusion |
| Augmentation renforc√©e | Meilleure g√©n√©ralisation |

---

## 7. R√©sultats

### 7.1 Classification Report

| Classe   | Pr√©cision | Recall | F1 | Support |
|----------|-----------|--------|-----|----------|
| elephant | 0.99 | 0.98 | 0.98 | 1000 |
| girafe   | 1.00 | 0.99 | 1.00 | 1000 |
| leopard  | 0.99 | 0.99 | 0.99 | 1000 |
| rhino    | 0.98 | 0.99 | 0.98 | 1000 |
| tigre    | 1.00 | 1.00 | 1.00 | 1000 |
| zebre    | 0.99 | 1.00 | 1.00 | 1000 |

### 7.2 M√©triques globales
- Accuracy : **~99 %**
- Macro-F1 : **0.99**
- Weighted-F1 : **0.99**

---

## 8. Export TFLite

### 8.1 Code

```python
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()
with open("cnn_model_animals_2025.tflite", "wb") as f:
    f.write(tflite_model)
```

### 8.2 V√©rification
- Diff√©rence max Keras vs TFLite : **0.000119**  
‚û°Ô∏è Sorties quasi identiques  

---

## 9. D√©ploiement Flutter

- Librairie : `tflite_flutter`  
- Entr√©e : `[1, 224, 224, 3]`  
- Pixels : **0‚Äì255**  
- Sortie : vecteur softmax (6 classes)  
- Labels : `model_labels.txt`  

---

## 10. Conclusion

EfficientNetB3 offre :

- Une pr√©cision proche du **state of the art**  
- Tr√®s faible confusion inter-classe  
- Excellente performance mobile (TFLite)  
- Pipeline clair, stable et reproductible  

---

## 11. Travaux futurs

- Quantization-aware training  
- Knowledge distillation  
- Visualisations Grad-CAM  
- Extension du dataset  

---

## 12. R√©f√©rences

- Tan & Le (2019). EfficientNet  
- Howard et al. (2017). MobileNet  
- Documentation TensorFlow Lite  
