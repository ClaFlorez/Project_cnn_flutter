
# ðŸ“– Explication pas Ã  pas du notebook `Model.ipynb`

Ce document explique **Ã©tape par Ã©tape** le code utilisÃ© pour entraÃ®ner un modÃ¨le de classification dâ€™images (animaux) avec TensorFlow/Keras dans Google Colab, puis lâ€™exporter pour une application Flutter via TensorFlow Lite.

Il est conÃ§u pour Ãªtre ajoutÃ© Ã  votre dÃ©pÃ´t GitHub, par exemple sous le nom :  
`docs/Model_Explication.md` ou `Model_Explication.md`.

---

## 1. Configuration de TensorFlow et du GPU

La premiÃ¨re section du notebook vÃ©rifie la version de TensorFlow et la disponibilitÃ© du GPU, puis configure lâ€™allocation mÃ©moire pour Ã©viter des erreurs dâ€™out of memory :

```python
import tensorflow as tf

print("Version de TensorFlow:", tf.__version__)
print("GPU disponible:", tf.config.list_physical_devices('GPU'))

gpus = tf.config.list_physical_devices('GPU')
if gpus:
    try:
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
        print("âœ… GPU configurÃ© avec memory growth.")
    except RuntimeError as e:
        print(e)
else:
    print("âš ï¸ Aucun GPU dÃ©tectÃ©, entraÃ®nement en CPU.")
```

**But :**
- VÃ©rifier que Colab utilise bien un GPU.
- Configurer le â€œmemory growthâ€ pour que TensorFlow nâ€™alloue pas toute la mÃ©moire GPU dâ€™un coup.

---

## 2. Imports principaux et paramÃ¨tres globaux

On importe toutes les bibliothÃ¨ques nÃ©cessaires : Numpy, Matplotlib, Seaborn, mÃ©triques de scikit-learn, ainsi que les modules Keras/TensorFlow.

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns

from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import (
    Conv2D, MaxPooling2D, Dense, Flatten, Dropout,
    BatchNormalization, Input, GlobalAveragePooling2D
)
from tensorflow.keras.callbacks import (
    EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard
)
import datetime
from pathlib import Path
import os
```

Ensuite, on dÃ©finit un dictionnaire de paramÃ¨tres (taille dâ€™image, batch size, nombre de classes, etc.) :

```python
PARAMS = {
    "img_height": 128,
    "img_width": 128,
    "img_channels": 3,
    "batch_size": 32,
    "learning_rate": 0.001,
    "num_classes": 6,   # elephant, girafe, leopard, rhino, tigre, zebre
    "epochs": 20
}
```

**But :**
- Centraliser tous les hyperparamÃ¨tres dans une seule structure.
- Permettre de modifier facilement la taille dâ€™image, le batch size ou le learning rate.

---

## 3. RÃ©cupÃ©ration du dataset depuis le dÃ©pÃ´t GitHub

Le notebook clone le dÃ©pÃ´t GitHub pour rÃ©cupÃ©rer les images dÃ©jÃ  organisÃ©es en 3 dossiers : `entrainement`, `validation`, `test`.

```python
!rm -rf /content/Project_cnn_flutter
!git clone https://github.com/ClaFlorez/Project_cnn_flutter.git /content/Project_cnn_flutter

BASE_DIR = "/content/Project_cnn_flutter"

DATA_PATHS = {
    "train":      f"{BASE_DIR}/entrainement",
    "validation": f"{BASE_DIR}/validation",
    "test":       f"{BASE_DIR}/test",
}
```

On vÃ©rifie ensuite que les dossiers existent et on affiche leur contenu :

```python
from pathlib import Path

print("\nðŸ“‚ VÃ©rification des dossiers du dataset :")
for split, path in DATA_PATHS.items():
    p = Path(path)
    print(f"- {split}: {p} â†’ existe:", p.exists())
    if p.exists():
        print("  Contenu:", os.listdir(p))
```

**But :**
- Sâ€™assurer que la structure du dataset est correcte aprÃ¨s le clonage.
- DÃ©tecter les classes en se basant sur les sous-dossiers de `entrainement`.

---

## 4. GÃ©nÃ©rateurs de donnÃ©es et augmentation

On utilise `ImageDataGenerator` pour :
- appliquer une **normalisation** systÃ©matique,
- et une **augmentation de donnÃ©es** sur lâ€™ensemble dâ€™entraÃ®nement.

```python
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    zoom_range=0.2,
    shear_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

val_test_datagen = ImageDataGenerator(rescale=1./255)
```

CrÃ©ation des gÃ©nÃ©rateurs :

```python
train_generator = train_datagen.flow_from_directory(
    DATA_PATHS["train"],
    target_size=(PARAMS["img_height"], PARAMS["img_width"]),
    batch_size=PARAMS["batch_size"],
    class_mode="categorical",
    shuffle=True
)

validation_generator = val_test_datagen.flow_from_directory(
    DATA_PATHS["validation"],
    target_size=(PARAMS["img_height"], PARAMS["img_width"]),
    batch_size=PARAMS["batch_size"],
    class_mode="categorical",
    shuffle=False
)

test_generator = val_test_datagen.flow_from_directory(
    DATA_PATHS["test"],
    target_size=(PARAMS["img_height"], PARAMS["img_width"]),
    batch_size=PARAMS["batch_size"],
    class_mode="categorical",
    shuffle=False
)

class_names = list(train_generator.class_indices.keys())
print("Classes dÃ©tectÃ©es :", class_names)
```

**But :**
- Normaliser les pixels dans [0,1].
- Enrichir le dataset dâ€™apprentissage via des transformations alÃ©atoires.
- Charger automatiquement les Ã©tiquettes en fonction des noms de dossiers.

---

## 5. DÃ©finition du modÃ¨le CNN

Le cÅ“ur du notebook est la fonction `create_cnn_model`, qui construit un modÃ¨le CNN compatible Keras 3 :

```python
def create_cnn_model(input_shape, num_classes):
    model = Sequential()
    model.add(Input(shape=input_shape))

    # Bloc 1
    model.add(Conv2D(32, (3,3), padding='same'))
    model.add(BatchNormalization())
    model.add(Activation('relu'))
    model.add(MaxPooling2D(2,2))
    model.add(Dropout(0.25))

    # Bloc 2
    model.add(Conv2D(64, (3,3), padding='same'))
    model.add(BatchNormalization())
    model.add(Activation('relu'))
    model.add(MaxPooling2D(2,2))
    model.add(Dropout(0.25))

    # Bloc 3
    model.add(Conv2D(128, (3,3), padding='same'))
    model.add(BatchNormalization())
    model.add(Activation('relu'))
    model.add(MaxPooling2D(2,2))
    model.add(Dropout(0.25))

    # Couches denses
    model.add(Flatten())
    model.add(Dense(256))
    model.add(BatchNormalization())
    model.add(Activation('relu'))
    model.add(Dropout(0.5))

    # Couche de sortie
    model.add(Dense(num_classes, activation='softmax'))

    # Compilation
    optimizer = Adam(learning_rate=PARAMS["learning_rate"])
    model.compile(
        optimizer=optimizer,
        loss="categorical_crossentropy",
        metrics=["accuracy"]
    )
    return model
```

CrÃ©ation dâ€™une instance du modÃ¨le :

```python
input_shape = (PARAMS["img_height"], PARAMS["img_width"], PARAMS["img_channels"])
model = create_cnn_model(input_shape, PARAMS["num_classes"])
model.summary()
```

**But :**
- Construire une architecture CNN adaptÃ©e Ã  des images 128Ã—128Ã—3.
- Utiliser BatchNorm + Dropout pour stabiliser et rÃ©gulariser lâ€™apprentissage.
- Utiliser Adam avec un learning rate de 0.001 (valeur standard).

---

## 6. Callbacks (EarlyStopping, ModelCheckpoint, ReduceLROnPlateau)

Pour fiabiliser lâ€™entraÃ®nement, le notebook configure plusieurs callbacks :

```python
import datetime

# Nom de base pour les fichiers (timestamp)
timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
model_name = f"cnn_model_{timestamp}"

SAVE_PATH = "/content/drive/MyDrive/models/"

checkpoint_path = SAVE_PATH + model_name + "_best.h5"

callbacks = [
    EarlyStopping(
        monitor="val_loss",
        patience=4,
        restore_best_weights=True
    ),
    ModelCheckpoint(
        checkpoint_path,
        monitor="val_loss",
        save_best_only=True
    ),
    ReduceLROnPlateau(
        monitor="val_loss",
        factor=0.5,
        patience=2,
        verbose=1
    )
]
```

**But :**
- Sauvegarder automatiquement le **meilleur modÃ¨le**.
- ArrÃªter lâ€™entraÃ®nement lorsque la validation ne sâ€™amÃ©liore plus.
- Diminuer le learning rate en cas de plateau.

---

## 7. EntraÃ®nement du modÃ¨le

```python
history = model.fit(
    train_generator,
    epochs=PARAMS["epochs"],
    validation_data=validation_generator,
    callbacks=callbacks
)
```

**But :**
- Lancer lâ€™apprentissage sur les images dâ€™animaux.
- Suivre la loss et lâ€™accuracy sur train et validation Ã  chaque Ã©poque.

---

## 8. Ã‰valuation, courbes et matrice de confusion

### 8.1 Ã‰valuation sur le set de test

```python
test_loss, test_acc = model.evaluate(test_generator)
print(f"Accuracy sur le set de test: {test_acc:.4f}")
```

### 8.2 Rapport de classification et matrice de confusion

```python
import numpy as np
from sklearn.metrics import classification_report, confusion_matrix

y_true = test_generator.classes
y_pred_probs = model.predict(test_generator)
y_pred = np.argmax(y_pred_probs, axis=1)

print(classification_report(y_true, y_pred, target_names=class_names))
```

```python
cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(8,6))
sns.heatmap(cm, annot=True, fmt="d",
            xticklabels=class_names,
            yticklabels=class_names,
            cmap="Blues")
plt.xlabel("PrÃ©dictions")
plt.ylabel("VÃ©ritÃ©s")
plt.title("Matrice de confusion")
plt.tight_layout()
plt.savefig(SAVE_PATH + model_name + "_confusion_matrix.png")
plt.show()
```

### 8.3 Courbes dâ€™apprentissage

```python
plt.figure(figsize=(12,5))

plt.subplot(1,2,1)
plt.plot(history.history["accuracy"], label="train acc")
plt.plot(history.history["val_accuracy"], label="val acc")
plt.title("Accuracy")
plt.legend()

plt.subplot(1,2,2)
plt.plot(history.history["loss"], label="train loss")
plt.plot(history.history["val_loss"], label="val loss")
plt.title("Loss")
plt.legend()

plt.tight_layout()
plt.savefig(SAVE_PATH + model_name + "_training_history.png")
plt.show()
```

---

## 9. Sauvegarde du modÃ¨le et export en TFLite

```python
full_model_path = SAVE_PATH + model_name + "_full_model.h5"
model.save(full_model_path)
print("ModÃ¨le complet sauvegardÃ© :", full_model_path)
```

```python
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

tflite_path = SAVE_PATH + model_name + ".tflite"
with open(tflite_path, "wb") as f:
    f.write(tflite_model)

print("ModÃ¨le TFLite sauvegardÃ© :", tflite_path)
```

```python
labels_path = SAVE_PATH + model_name + "_labels.txt"
with open(labels_path, "w") as f:
    for label in class_names:
        f.write(label + "\n")

print("Labels sauvegardÃ©s dans :", labels_path)
```

---

## 10. Instructions Flutter gÃ©nÃ©rÃ©es automatiquement

```python
flutter_instructions_path = SAVE_PATH + model_name + "_flutter_instructions.txt"

instructions = f"""INTEGRATION FLUTTER DU MODELE: {model_name}.tflite

1. Copier les fichiers suivants dans votre projet Flutter:
   - assets/models/{model_name}.tflite
   - assets/models/{model_name}_labels.txt

2. Mettre Ã  jour pubspec.yaml:

flutter:
  assets:
    - assets/models/{model_name}.tflite
    - assets/models/{model_name}_labels.txt

3. Utiliser tflite_flutter (ou Ã©quivalent) pour charger le modÃ¨le et faire des prÃ©dictions.
"""

with open(flutter_instructions_path, "w") as f:
    f.write(instructions)

print("Instructions Flutter sauvegardÃ©es dans :", flutter_instructions_path)
```

---

## 11. RÃ©sumÃ© final

```python
summary = f"""FICHIERS GÃ‰NÃ‰RÃ‰S:
-----------------
1. {model_name}_full_model.h5
2. {model_name}_best.h5
3. {model_name}.tflite
4. {model_name}_labels.txt
5. {model_name}_training_history.png
6. {model_name}_confusion_matrix.png
7. {model_name}_flutter_instructions.txt

PARAMÃˆTRES PRINCIPAUX:
----------------------
- Taille images: {PARAMS['img_height']}x{PARAMS['img_width']}
- Batch size: {PARAMS['batch_size']}
- Learning rate: {PARAMS['learning_rate']}
- Nombre classes: {PARAMS['num_classes']}
- Classes: {class_names}
- GPU utilisÃ©: {len(gpus) > 0}

Tous les fichiers sont sauvegardÃ©s dans: {SAVE_PATH}
"""

print(summary)

with open(SAVE_PATH + model_name + "_summary.txt", "w") as f:
    f.write(summary)

print("\nâœ“ TP TERMINÃ‰ AVEC SUCCÃˆS! âœ“\n")
```

---

