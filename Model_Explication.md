
# üìñ Explication pas √† pas du notebook `Model.ipynb`

Ce document explique **√©tape par √©tape** le code utilis√© pour entra√Æner un mod√®le de classification d‚Äôimages (animaux) avec TensorFlow/Keras dans Google Colab, puis l‚Äôexporter pour une application Flutter via TensorFlow Lite.

Il est con√ßu pour √™tre ajout√© √† votre d√©p√¥t GitHub, par exemple sous le nom :  
`docs/Model_Explication.md` ou `Model_Explication.md`.

---

## 1. Configuration de TensorFlow et du GPU

La premi√®re section du notebook v√©rifie la version de TensorFlow et la disponibilit√© du GPU, puis configure l‚Äôallocation m√©moire pour √©viter des erreurs d‚Äôout of memory :

```python
import tensorflow as tf

print("Version de TensorFlow:", tf.__version__)
print("GPU disponible:", tf.config.list_physical_devices('GPU'))

gpus = tf.config.list_physical_devices('GPU')
if gpus:
    try:
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
        print("‚úÖ GPU configur√© avec memory growth.")
    except RuntimeError as e:
        print(e)
else:
    print("‚ö†Ô∏è Aucun GPU d√©tect√©, entra√Ænement en CPU.")
```

**But :**
- V√©rifier que Colab utilise bien un GPU.
- Configurer le ‚Äúmemory growth‚Äù pour que TensorFlow n‚Äôalloue pas toute la m√©moire GPU d‚Äôun coup.

---

## 2. Imports principaux et param√®tres globaux

On importe toutes les biblioth√®ques n√©cessaires : Numpy, Matplotlib, Seaborn, m√©triques de scikit-learn, ainsi que les modules Keras/TensorFlow.

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns

from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import (
    Conv2D, MaxPooling2D, Dense, Flatten, Dropout,
    BatchNormalization, Input, GlobalAveragePooling2D
)
from tensorflow.keras.callbacks import (
    EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard
)
import datetime
from pathlib import Path
import os
```

Ensuite, on d√©finit un dictionnaire de param√®tres (taille d‚Äôimage, batch size, nombre de classes, etc.) :

```python
PARAMS = {
    "img_height": 128,
    "img_width": 128,
    "img_channels": 3,
    "batch_size": 32,
    "learning_rate": 0.001,
    "num_classes": 6,   # elephant, girafe, leopard, rhino, tigre, zebre
    "epochs": 20
}
```

**But :**
- Centraliser tous les hyperparam√®tres dans une seule structure.
- Permettre de modifier facilement la taille d‚Äôimage, le batch size ou le learning rate.

---

## 3. R√©cup√©ration du dataset depuis le d√©p√¥t GitHub

Le notebook clone le d√©p√¥t GitHub pour r√©cup√©rer les images d√©j√† organis√©es en 3 dossiers : `entrainement`, `validation`, `test`.

```python
!rm -rf /content/Project_cnn_flutter
!git clone https://github.com/ClaFlorez/Project_cnn_flutter.git /content/Project_cnn_flutter

BASE_DIR = "/content/Project_cnn_flutter"

DATA_PATHS = {
    "train":      f"{BASE_DIR}/entrainement",
    "validation": f"{BASE_DIR}/validation",
    "test":       f"{BASE_DIR}/test",
}
```

On v√©rifie ensuite que les dossiers existent et on affiche leur contenu :

```python
from pathlib import Path

print("\nüìÇ V√©rification des dossiers du dataset :")
for split, path in DATA_PATHS.items():
    p = Path(path)
    print(f"- {split}: {p} ‚Üí existe:", p.exists())
    if p.exists():
        print("  Contenu:", os.listdir(p))
```

**But :**
- S‚Äôassurer que la structure du dataset est correcte apr√®s le clonage.
- D√©tecter les classes en se basant sur les sous-dossiers de `entrainement`.

---

## 4. G√©n√©rateurs de donn√©es et augmentation

On utilise `ImageDataGenerator` pour :
- appliquer une **normalisation** syst√©matique,
- et une **augmentation de donn√©es** sur l‚Äôensemble d‚Äôentra√Ænement.

```python
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    zoom_range=0.2,
    shear_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

val_test_datagen = ImageDataGenerator(rescale=1./255)
```

Cr√©ation des g√©n√©rateurs :

```python
train_generator = train_datagen.flow_from_directory(
    DATA_PATHS["train"],
    target_size=(PARAMS["img_height"], PARAMS["img_width"]),
    batch_size=PARAMS["batch_size"],
    class_mode="categorical",
    shuffle=True
)

validation_generator = val_test_datagen.flow_from_directory(
    DATA_PATHS["validation"],
    target_size=(PARAMS["img_height"], PARAMS["img_width"]),
    batch_size=PARAMS["batch_size"],
    class_mode="categorical",
    shuffle=False
)

test_generator = val_test_datagen.flow_from_directory(
    DATA_PATHS["test"],
    target_size=(PARAMS["img_height"], PARAMS["img_width"]),
    batch_size=PARAMS["batch_size"],
    class_mode="categorical",
    shuffle=False
)

class_names = list(train_generator.class_indices.keys())
print("Classes d√©tect√©es :", class_names)
```

**But :**
- Normaliser les pixels dans [0,1].
- Enrichir le dataset d‚Äôapprentissage via des transformations al√©atoires.
- Charger automatiquement les √©tiquettes en fonction des noms de dossiers.

---

## 5. D√©finition du mod√®le CNN

Le c≈ìur du notebook est la fonction `create_cnn_model`, qui construit un mod√®le CNN compatible Keras 3 :

```python
def create_cnn_model(input_shape, num_classes):
    model = Sequential()
    model.add(Input(shape=input_shape))

    # Bloc 1
    model.add(Conv2D(32, (3,3), padding='same'))
    model.add(BatchNormalization())
    model.add(Activation('relu'))
    model.add(MaxPooling2D(2,2))
    model.add(Dropout(0.25))

    # Bloc 2
    model.add(Conv2D(64, (3,3), padding='same'))
    model.add(BatchNormalization())
    model.add(Activation('relu'))
    model.add(MaxPooling2D(2,2))
    model.add(Dropout(0.25))

    # Bloc 3
    model.add(Conv2D(128, (3,3), padding='same'))
    model.add(BatchNormalization())
    model.add(Activation('relu'))
    model.add(MaxPooling2D(2,2))
    model.add(Dropout(0.25))

    # Couches denses
    model.add(Flatten())
    model.add(Dense(256))
    model.add(BatchNormalization())
    model.add(Activation('relu'))
    model.add(Dropout(0.5))

    # Couche de sortie
    model.add(Dense(num_classes, activation='softmax'))

    # Compilation
    optimizer = Adam(learning_rate=PARAMS["learning_rate"])
    model.compile(
        optimizer=optimizer,
        loss="categorical_crossentropy",
        metrics=["accuracy"]
    )
    return model
```

Cr√©ation d‚Äôune instance du mod√®le :

```python
input_shape = (PARAMS["img_height"], PARAMS["img_width"], PARAMS["img_channels"])
model = create_cnn_model(input_shape, PARAMS["num_classes"])
model.summary()
```

**But :**
- Construire une architecture CNN adapt√©e √† des images 128√ó128√ó3.
- Utiliser BatchNorm + Dropout pour stabiliser et r√©gulariser l‚Äôapprentissage.
- Utiliser Adam avec un learning rate de 0.001 (valeur standard).

---

## 6. Callbacks (EarlyStopping, ModelCheckpoint, ReduceLROnPlateau)

Pour fiabiliser l‚Äôentra√Ænement, le notebook configure plusieurs callbacks :

```python
import datetime

# Nom de base pour les fichiers (timestamp)
timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
model_name = f"cnn_model_{timestamp}"

SAVE_PATH = "/content/drive/MyDrive/models/"

checkpoint_path = SAVE_PATH + model_name + "_best.h5"

callbacks = [
    EarlyStopping(
        monitor="val_loss",
        patience=4,
        restore_best_weights=True
    ),
    ModelCheckpoint(
        checkpoint_path,
        monitor="val_loss",
        save_best_only=True
    ),
    ReduceLROnPlateau(
        monitor="val_loss",
        factor=0.5,
        patience=2,
        verbose=1
    )
]
```

**But :**
- Sauvegarder automatiquement le **meilleur mod√®le**.
- Arr√™ter l‚Äôentra√Ænement lorsque la validation ne s‚Äôam√©liore plus.
- Diminuer le learning rate en cas de plateau.

---

## 7. Entra√Ænement du mod√®le

```python
history = model.fit(
    train_generator,
    epochs=PARAMS["epochs"],
    validation_data=validation_generator,
    callbacks=callbacks
)
```

**But :**
- Lancer l‚Äôapprentissage sur les images d‚Äôanimaux.
- Suivre la loss et l‚Äôaccuracy sur train et validation √† chaque √©poque.

---

## 8. √âvaluation, courbes et matrice de confusion

### 8.1 √âvaluation sur le set de test

```python
test_loss, test_acc = model.evaluate(test_generator)
print(f"Accuracy sur le set de test: {test_acc:.4f}")
```

### 8.2 Rapport de classification et matrice de confusion

```python
import numpy as np
from sklearn.metrics import classification_report, confusion_matrix

y_true = test_generator.classes
y_pred_probs = model.predict(test_generator)
y_pred = np.argmax(y_pred_probs, axis=1)

print(classification_report(y_true, y_pred, target_names=class_names))
```

```python
cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(8,6))
sns.heatmap(cm, annot=True, fmt="d",
            xticklabels=class_names,
            yticklabels=class_names,
            cmap="Blues")
plt.xlabel("Pr√©dictions")
plt.ylabel("V√©rit√©s")
plt.title("Matrice de confusion")
plt.tight_layout()
plt.savefig(SAVE_PATH + model_name + "_confusion_matrix.png")
plt.show()
```

### 8.3 Courbes d‚Äôapprentissage

```python
plt.figure(figsize=(12,5))

plt.subplot(1,2,1)
plt.plot(history.history["accuracy"], label="train acc")
plt.plot(history.history["val_accuracy"], label="val acc")
plt.title("Accuracy")
plt.legend()

plt.subplot(1,2,2)
plt.plot(history.history["loss"], label="train loss")
plt.plot(history.history["val_loss"], label="val loss")
plt.title("Loss")
plt.legend()

plt.tight_layout()
plt.savefig(SAVE_PATH + model_name + "_training_history.png")
plt.show()
```

---

## 9. Sauvegarde du mod√®le et export en TFLite

```python
full_model_path = SAVE_PATH + model_name + "_full_model.h5"
model.save(full_model_path)
print("Mod√®le complet sauvegard√© :", full_model_path)
```

```python
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

tflite_path = SAVE_PATH + model_name + ".tflite"
with open(tflite_path, "wb") as f:
    f.write(tflite_model)

print("Mod√®le TFLite sauvegard√© :", tflite_path)
```

```python
labels_path = SAVE_PATH + model_name + "_labels.txt"
with open(labels_path, "w") as f:
    for label in class_names:
        f.write(label + "\n")

print("Labels sauvegard√©s dans :", labels_path)
```

---

## 10. Instructions Flutter g√©n√©r√©es automatiquement

```python
flutter_instructions_path = SAVE_PATH + model_name + "_flutter_instructions.txt"

instructions = f"""INTEGRATION FLUTTER DU MODELE: {model_name}.tflite

1. Copier les fichiers suivants dans votre projet Flutter:
   - assets/models/{model_name}.tflite
   - assets/models/{model_name}_labels.txt

2. Mettre √† jour pubspec.yaml:

flutter:
  assets:
    - assets/models/{model_name}.tflite
    - assets/models/{model_name}_labels.txt

3. Utiliser tflite_flutter (ou √©quivalent) pour charger le mod√®le et faire des pr√©dictions.
"""

with open(flutter_instructions_path, "w") as f:
    f.write(instructions)

print("Instructions Flutter sauvegard√©es dans :", flutter_instructions_path)
```

---

## 11. R√©sum√© final

```python
summary = f"""FICHIERS G√âN√âR√âS:
-----------------
1. {model_name}_full_model.h5
2. {model_name}_best.h5
3. {model_name}.tflite
4. {model_name}_labels.txt
5. {model_name}_training_history.png
6. {model_name}_confusion_matrix.png
7. {model_name}_flutter_instructions.txt

PARAM√àTRES PRINCIPAUX:
----------------------
- Taille images: {PARAMS['img_height']}x{PARAMS['img_width']}
- Batch size: {PARAMS['batch_size']}
- Learning rate: {PARAMS['learning_rate']}
- Nombre classes: {PARAMS['num_classes']}
- Classes: {class_names}
- GPU utilis√©: {len(gpus) > 0}

Tous les fichiers sont sauvegard√©s dans: {SAVE_PATH}
"""

print(summary)

with open(SAVE_PATH + model_name + "_summary.txt", "w") as f:
    f.write(summary)

print("\n‚úì TP TERMIN√â AVEC SUCC√àS! ‚úì\n")
```

---

## 12. Int√©gration dans GitHub

Ajoutez ce fichier dans votre d√©p√¥t (par exemple `Model_Explication.md`) et cr√©ez un lien depuis votre `README.md` :

```markdown
Pour une explication d√©taill√©e du notebook d‚Äôentra√Ænement, voir :
[Explication pas √† pas du mod√®le](Model_Explication.md)
```

Ce document est pens√© comme une **documentation p√©dagogique** de votre code, utile pour :
- les correcteurs du TP
- vos futurs projets
- toute personne souhaitant comprendre ou r√©utiliser votre pipeline.
